{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53033d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:07:52.438545Z",
     "iopub.status.busy": "2025-12-24T20:07:52.438262Z",
     "iopub.status.idle": "2025-12-24T20:07:53.139946Z",
     "shell.execute_reply": "2025-12-24T20:07:53.139164Z"
    },
    "papermill": {
     "duration": 0.71063,
     "end_time": "2025-12-24T20:07:53.141749",
     "exception": false,
     "start_time": "2025-12-24T20:07:52.431119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)      # show all columns\n",
    "pd.set_option(\"display.max_colwidth\", None)     # show full cell content\n",
    "pd.set_option(\"display.width\", None)            # no line wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cebc183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:07:53.153046Z",
     "iopub.status.busy": "2025-12-24T20:07:53.152717Z",
     "iopub.status.idle": "2025-12-24T20:08:35.051208Z",
     "shell.execute_reply": "2025-12-24T20:08:35.050442Z"
    },
    "papermill": {
     "duration": 41.906243,
     "end_time": "2025-12-24T20:08:35.053270",
     "exception": false,
     "start_time": "2025-12-24T20:07:53.147027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q /kaggle/input/create-pairs-from-processed-morph-cacd-agedb-fgnet/_output_.zip -d /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5142e8d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:35.064721Z",
     "iopub.status.busy": "2025-12-24T20:08:35.064453Z",
     "iopub.status.idle": "2025-12-24T20:08:35.069865Z",
     "shell.execute_reply": "2025-12-24T20:08:35.068961Z"
    },
    "papermill": {
     "duration": 0.012954,
     "end_time": "2025-12-24T20:08:35.071440",
     "exception": false,
     "start_time": "2025-12-24T20:08:35.058486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgeDB_processed', 'AgeDB_processed.csv', 'CACD_processed', 'CACD_processed.csv', 'FGNET_processed', 'FGNET_processed.csv', 'MORPH_processed', 'MORPH_processed.csv', '__notebook__.ipynb', '__pycache__', 'morph_cacd_agedb_fgnet.csv', 'morph_cacd_agedb_fgnet_updated.csv', 'train_data']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "path = \"/kaggle/working/\"\n",
    "files = sorted(os.listdir(path))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aad0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:35.082745Z",
     "iopub.status.busy": "2025-12-24T20:08:35.082509Z",
     "iopub.status.idle": "2025-12-24T20:08:35.470902Z",
     "shell.execute_reply": "2025-12-24T20:08:35.470313Z"
    },
    "papermill": {
     "duration": 0.395786,
     "end_time": "2025-12-24T20:08:35.472620",
     "exception": false,
     "start_time": "2025-12-24T20:08:35.076834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "morph_cacd_agedb_fgnet = pd.read_csv(\"/kaggle/working/morph_cacd_agedb_fgnet_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abe5583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:35.483943Z",
     "iopub.status.busy": "2025-12-24T20:08:35.483699Z",
     "iopub.status.idle": "2025-12-24T20:08:35.505537Z",
     "shell.execute_reply": "2025-12-24T20:08:35.504882Z"
    },
    "papermill": {
     "duration": 0.029017,
     "end_time": "2025-12-24T20:08:35.506905",
     "exception": false,
     "start_time": "2025-12-24T20:08:35.477888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AgeDB_BurtLancaster</td>\n",
       "      <td>56</td>\n",
       "      <td>m</td>\n",
       "      <td>BurtLancaster_56_m_000000.jpg</td>\n",
       "      <td>/kaggle/working/AgeDB_processed/BurtLancaster/BurtLancaster_56_m_000000.jpg</td>\n",
       "      <td>AgeDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AgeDB_GordonThomson</td>\n",
       "      <td>64</td>\n",
       "      <td>m</td>\n",
       "      <td>GordonThomson_64_m_000001.jpg</td>\n",
       "      <td>/kaggle/working/AgeDB_processed/GordonThomson/GordonThomson_64_m_000001.jpg</td>\n",
       "      <td>AgeDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgeDB_angelamerkel</td>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "      <td>angelamerkel_20_f_000002.jpg</td>\n",
       "      <td>/kaggle/working/AgeDB_processed/angelamerkel/angelamerkel_20_f_000002.jpg</td>\n",
       "      <td>AgeDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AgeDB_LawrenceTierney</td>\n",
       "      <td>34</td>\n",
       "      <td>m</td>\n",
       "      <td>LawrenceTierney_34_m_000003.jpg</td>\n",
       "      <td>/kaggle/working/AgeDB_processed/LawrenceTierney/LawrenceTierney_34_m_000003.jpg</td>\n",
       "      <td>AgeDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AgeDB_JamesWoods</td>\n",
       "      <td>54</td>\n",
       "      <td>m</td>\n",
       "      <td>JamesWoods_54_m_000004.jpg</td>\n",
       "      <td>/kaggle/working/AgeDB_processed/JamesWoods/JamesWoods_54_m_000004.jpg</td>\n",
       "      <td>AgeDB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                identity  age gender                         filename  \\\n",
       "0    AgeDB_BurtLancaster   56      m    BurtLancaster_56_m_000000.jpg   \n",
       "1    AgeDB_GordonThomson   64      m    GordonThomson_64_m_000001.jpg   \n",
       "2     AgeDB_angelamerkel   20      f     angelamerkel_20_f_000002.jpg   \n",
       "3  AgeDB_LawrenceTierney   34      m  LawrenceTierney_34_m_000003.jpg   \n",
       "4       AgeDB_JamesWoods   54      m       JamesWoods_54_m_000004.jpg   \n",
       "\n",
       "                                                                          filepath  \\\n",
       "0      /kaggle/working/AgeDB_processed/BurtLancaster/BurtLancaster_56_m_000000.jpg   \n",
       "1      /kaggle/working/AgeDB_processed/GordonThomson/GordonThomson_64_m_000001.jpg   \n",
       "2        /kaggle/working/AgeDB_processed/angelamerkel/angelamerkel_20_f_000002.jpg   \n",
       "3  /kaggle/working/AgeDB_processed/LawrenceTierney/LawrenceTierney_34_m_000003.jpg   \n",
       "4            /kaggle/working/AgeDB_processed/JamesWoods/JamesWoods_54_m_000004.jpg   \n",
       "\n",
       "  dataset  \n",
       "0   AgeDB  \n",
       "1   AgeDB  \n",
       "2   AgeDB  \n",
       "3   AgeDB  \n",
       "4   AgeDB  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_cacd_agedb_fgnet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a859493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:35.519590Z",
     "iopub.status.busy": "2025-12-24T20:08:35.518970Z",
     "iopub.status.idle": "2025-12-24T20:08:35.523329Z",
     "shell.execute_reply": "2025-12-24T20:08:35.522754Z"
    },
    "papermill": {
     "duration": 0.011425,
     "end_time": "2025-12-24T20:08:35.524743",
     "exception": false,
     "start_time": "2025-12-24T20:08:35.513318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174051"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morph_cacd_agedb_fgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee6d1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:35.536252Z",
     "iopub.status.busy": "2025-12-24T20:08:35.535829Z",
     "iopub.status.idle": "2025-12-24T20:08:35.541106Z",
     "shell.execute_reply": "2025-12-24T20:08:35.540548Z"
    },
    "papermill": {
     "duration": 0.012622,
     "end_time": "2025-12-24T20:08:35.542437",
     "exception": false,
     "start_time": "2025-12-24T20:08:35.529815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identity    object\n",
       "age          int64\n",
       "gender      object\n",
       "filename    object\n",
       "filepath    object\n",
       "dataset     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_cacd_agedb_fgnet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb60957a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:35.554141Z",
     "iopub.status.busy": "2025-12-24T20:08:35.553829Z",
     "iopub.status.idle": "2025-12-24T20:08:36.303416Z",
     "shell.execute_reply": "2025-12-24T20:08:36.302556Z"
    },
    "papermill": {
     "duration": 0.75737,
     "end_time": "2025-12-24T20:08:36.305020",
     "exception": false,
     "start_time": "2025-12-24T20:08:35.547650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files       : 174051\n",
      "Existing files    : 174014\n",
      "Missing files     : 37\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "exists_count = 0\n",
    "missing_count = 0\n",
    "missing_files = []\n",
    "\n",
    "for path in morph_cacd_agedb_fgnet['filepath']:\n",
    "    if pd.isna(path):\n",
    "        missing_count += 1\n",
    "        missing_files.append(path)\n",
    "    elif os.path.exists(str(path)):\n",
    "        exists_count += 1\n",
    "    else:\n",
    "        missing_count += 1\n",
    "        missing_files.append(path)\n",
    "\n",
    "print(f\"Total files       : {len(morph_cacd_agedb_fgnet)}\")\n",
    "print(f\"Existing files    : {exists_count}\")\n",
    "print(f\"Missing files     : {missing_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c816a971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:36.317027Z",
     "iopub.status.busy": "2025-12-24T20:08:36.316491Z",
     "iopub.status.idle": "2025-12-24T20:08:36.337569Z",
     "shell.execute_reply": "2025-12-24T20:08:36.336949Z"
    },
    "papermill": {
     "duration": 0.028461,
     "end_time": "2025-12-24T20:08:36.338905",
     "exception": false,
     "start_time": "2025-12-24T20:08:36.310444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169938</th>\n",
       "      <td>FGNET_nan</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170066</th>\n",
       "      <td>FGNET_nan</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170108</th>\n",
       "      <td>FGNET_nan</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170123</th>\n",
       "      <td>FGNET_nan</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170137</th>\n",
       "      <td>FGNET_nan</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGNET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         identity  age gender filename filepath dataset\n",
       "169938  FGNET_nan   33    NaN      NaN      NaN   FGNET\n",
       "170066  FGNET_nan   40    NaN      NaN      NaN   FGNET\n",
       "170108  FGNET_nan    4    NaN      NaN      NaN   FGNET\n",
       "170123  FGNET_nan    8    NaN      NaN      NaN   FGNET\n",
       "170137  FGNET_nan   22    NaN      NaN      NaN   FGNET"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_cacd_agedb_fgnet[\n",
    "    morph_cacd_agedb_fgnet['filepath'].isna()\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55947af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:36.350709Z",
     "iopub.status.busy": "2025-12-24T20:08:36.350292Z",
     "iopub.status.idle": "2025-12-24T20:08:37.059146Z",
     "shell.execute_reply": "2025-12-24T20:08:37.058319Z"
    },
    "papermill": {
     "duration": 0.716491,
     "end_time": "2025-12-24T20:08:37.060710",
     "exception": false,
     "start_time": "2025-12-24T20:08:36.344219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning : 174051\n",
      "After cleaning  : 174014\n",
      "Dropped rows    : 37\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Keep only rows with valid existing file paths\n",
    "mask_exists = (\n",
    "    morph_cacd_agedb_fgnet['filepath'].notna() &\n",
    "    morph_cacd_agedb_fgnet['filepath'].apply(lambda x: os.path.exists(str(x)))\n",
    ")\n",
    "\n",
    "morph_cacd_agedb_fgnet_clean = morph_cacd_agedb_fgnet[mask_exists].reset_index(drop=True)\n",
    "\n",
    "print(f\"Before cleaning : {len(morph_cacd_agedb_fgnet)}\")\n",
    "print(f\"After cleaning  : {len(morph_cacd_agedb_fgnet_clean)}\")\n",
    "print(f\"Dropped rows    : {len(morph_cacd_agedb_fgnet) - len(morph_cacd_agedb_fgnet_clean)}\")\n",
    "\n",
    "\n",
    "morph_cacd_agedb_fgnet = morph_cacd_agedb_fgnet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b8d03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:37.072993Z",
     "iopub.status.busy": "2025-12-24T20:08:37.072743Z",
     "iopub.status.idle": "2025-12-24T20:08:37.746603Z",
     "shell.execute_reply": "2025-12-24T20:08:37.745742Z"
    },
    "papermill": {
     "duration": 0.681629,
     "end_time": "2025-12-24T20:08:37.748091",
     "exception": false,
     "start_time": "2025-12-24T20:08:37.066462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files       : 174014\n",
      "Existing files    : 174014\n",
      "Missing files     : 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Assume your DataFrame is called `cacd`\n",
    "# and the column name is exactly `filepath`\n",
    "\n",
    "exists_count = 0\n",
    "missing_count = 0\n",
    "missing_files = []\n",
    "\n",
    "for path in morph_cacd_agedb_fgnet['filepath']:\n",
    "    if os.path.exists(path):\n",
    "        exists_count += 1\n",
    "    else:\n",
    "        missing_count += 1\n",
    "        missing_files.append(path)\n",
    "\n",
    "print(f\"Total files       : {len(morph_cacd_agedb_fgnet)}\")\n",
    "print(f\"Existing files    : {exists_count}\")\n",
    "print(f\"Missing files     : {missing_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433a385",
   "metadata": {
    "papermill": {
     "duration": 0.005347,
     "end_time": "2025-12-24T20:08:37.759125",
     "exception": false,
     "start_time": "2025-12-24T20:08:37.753778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186688ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:37.770897Z",
     "iopub.status.busy": "2025-12-24T20:08:37.770648Z",
     "iopub.status.idle": "2025-12-24T20:08:38.340894Z",
     "shell.execute_reply": "2025-12-24T20:08:38.339958Z"
    },
    "papermill": {
     "duration": 0.57789,
     "end_time": "2025-12-24T20:08:38.342391",
     "exception": false,
     "start_time": "2025-12-24T20:08:37.764501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned file to: /kaggle/working/morph_cacd_agedb_fgnet_clean.csv\n",
      "Final number of rows: 174014\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned DataFrame\n",
    "output_path = \"/kaggle/working/morph_cacd_agedb_fgnet_clean.csv\"\n",
    "morph_cacd_agedb_fgnet_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved cleaned file to: {output_path}\")\n",
    "print(f\"Final number of rows: {len(morph_cacd_agedb_fgnet_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4cb228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:38.354657Z",
     "iopub.status.busy": "2025-12-24T20:08:38.354410Z",
     "iopub.status.idle": "2025-12-24T20:08:38.389680Z",
     "shell.execute_reply": "2025-12-24T20:08:38.388899Z"
    },
    "papermill": {
     "duration": 0.04283,
     "end_time": "2025-12-24T20:08:38.391021",
     "exception": false,
     "start_time": "2025-12-24T20:08:38.348191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paths           : 174014\n",
      "Paths WITH spaces     : 0\n",
      "Paths WITHOUT spaces  : 174014\n"
     ]
    }
   ],
   "source": [
    "# Boolean mask: True if filepath contains at least one space\n",
    "has_space = morph_cacd_agedb_fgnet[\"filepath\"].str.contains(\" \", regex=False)\n",
    "\n",
    "# Counts\n",
    "total_paths = len(morph_cacd_agedb_fgnet)\n",
    "paths_with_space = has_space.sum()\n",
    "paths_without_space = total_paths - paths_with_space\n",
    "\n",
    "print(f\"Total paths           : {total_paths}\")\n",
    "print(f\"Paths WITH spaces     : {paths_with_space}\")\n",
    "print(f\"Paths WITHOUT spaces  : {paths_without_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29258e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:38.403517Z",
     "iopub.status.busy": "2025-12-24T20:08:38.402894Z",
     "iopub.status.idle": "2025-12-24T20:08:38.416682Z",
     "shell.execute_reply": "2025-12-24T20:08:38.416121Z"
    },
    "papermill": {
     "duration": 0.021373,
     "end_time": "2025-12-24T20:08:38.417996",
     "exception": false,
     "start_time": "2025-12-24T20:08:38.396623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3236"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morph_cacd_agedb_fgnet['identity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758d278",
   "metadata": {
    "papermill": {
     "duration": 0.005306,
     "end_time": "2025-12-24T20:08:38.428802",
     "exception": false,
     "start_time": "2025-12-24T20:08:38.423496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61795d0",
   "metadata": {
    "papermill": {
     "duration": 0.005368,
     "end_time": "2025-12-24T20:08:38.439605",
     "exception": false,
     "start_time": "2025-12-24T20:08:38.434237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c2b489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:38.451610Z",
     "iopub.status.busy": "2025-12-24T20:08:38.451277Z",
     "iopub.status.idle": "2025-12-24T20:08:43.072947Z",
     "shell.execute_reply": "2025-12-24T20:08:43.072219Z"
    },
    "papermill": {
     "duration": 4.629897,
     "end_time": "2025-12-24T20:08:43.074898",
     "exception": false,
     "start_time": "2025-12-24T20:08:38.445001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q onnx onnx2pytorch accelerate scikit-learn scipy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b8afb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:43.092417Z",
     "iopub.status.busy": "2025-12-24T20:08:43.091917Z",
     "iopub.status.idle": "2025-12-24T20:08:46.160936Z",
     "shell.execute_reply": "2025-12-24T20:08:46.160059Z"
    },
    "papermill": {
     "duration": 3.077796,
     "end_time": "2025-12-24T20:08:46.163060",
     "exception": false,
     "start_time": "2025-12-24T20:08:43.085264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c02aa5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:46.176261Z",
     "iopub.status.busy": "2025-12-24T20:08:46.175693Z",
     "iopub.status.idle": "2025-12-24T20:08:46.423305Z",
     "shell.execute_reply": "2025-12-24T20:08:46.422583Z"
    },
    "papermill": {
     "duration": 0.255883,
     "end_time": "2025-12-24T20:08:46.424793",
     "exception": false,
     "start_time": "2025-12-24T20:08:46.168910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All rows have exactly 5 values. File is CLEAN!\n",
      "\n",
      "‚úÖ Total checked rows: 277828\n",
      "‚ùå Total bad rows: 0\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/working/train_data/all_pairs.txt\"\n",
    "\n",
    "bad_rows = []\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line_num, line in enumerate(f, start=1):\n",
    "        line = line.strip()\n",
    "\n",
    "        # Skip empty lines safely\n",
    "        if not line:\n",
    "            bad_rows.append((line_num, 0, \"EMPTY LINE\"))\n",
    "            continue\n",
    "\n",
    "        values = line.split()  # split on spaces\n",
    "        num_values = len(values)\n",
    "\n",
    "        if num_values != 5:\n",
    "            bad_rows.append((line_num, num_values, line))\n",
    "\n",
    "# ---------- REPORT ----------\n",
    "if bad_rows:\n",
    "    print(f\"\\n‚ùå Found {len(bad_rows)} bad rows:\\n\")\n",
    "    # for row in bad_rows:\n",
    "    #     print(f\"Line {row[0]} -> {row[1]} values:\")\n",
    "    #     print(row[2])\n",
    "    #     print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All rows have exactly 5 values. File is CLEAN!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total checked rows: {line_num}\")\n",
    "print(f\"‚ùå Total bad rows: {len(bad_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa8f35bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:46.437302Z",
     "iopub.status.busy": "2025-12-24T20:08:46.437011Z",
     "iopub.status.idle": "2025-12-24T20:08:46.556217Z",
     "shell.execute_reply": "2025-12-24T20:08:46.555421Z"
    },
    "papermill": {
     "duration": 0.126963,
     "end_time": "2025-12-24T20:08:46.557740",
     "exception": false,
     "start_time": "2025-12-24T20:08:46.430777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/MORPH_processed/69975/69975_54_m_045703.jpg /kaggle/working/MORPH_processed/8332/8332_16_m_049868.jpg 0 0 38.0\r\n",
      "/kaggle/working/CACD_processed/1995/1995_19_f_154594.jpg /kaggle/working/CACD_processed/454/454_49_m_031592.jpg 0 0 30.0\r\n",
      "/kaggle/working/AgeDB_processed/MaureenOHara/MaureenOHara_78_f_002181.jpg /kaggle/working/CACD_processed/685/685_48_m_048949.jpg 0 0 30.0\r\n",
      "/kaggle/working/FGNET_processed/020A36.JPG /kaggle/working/CACD_processed/505/505_47_m_035080.jpg 0 0 11.0\r\n",
      "/kaggle/working/CACD_processed/628/628_46_m_044396.jpg /kaggle/working/CACD_processed/628/628_48_m_044415.jpg 1 1 2.0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 /kaggle/working/train_data/all_pairs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54dc7ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:46.571966Z",
     "iopub.status.busy": "2025-12-24T20:08:46.571730Z",
     "iopub.status.idle": "2025-12-24T20:08:47.877527Z",
     "shell.execute_reply": "2025-12-24T20:08:47.876624Z"
    },
    "papermill": {
     "duration": 1.315513,
     "end_time": "2025-12-24T20:08:47.879049",
     "exception": false,
     "start_time": "2025-12-24T20:08:46.563536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ ALL FILE\n",
      "Total rows   : 277828\n",
      "Invalid rows : 121\n",
      "Valid rows   : 277707\n",
      "\n",
      "üìÇ TRAIN FILE\n",
      "Total rows   : 222262\n",
      "Invalid rows : 98\n",
      "Valid rows   : 222164\n",
      "\n",
      "üìÇ VAL FILE\n",
      "Total rows   : 55566\n",
      "Invalid rows : 23\n",
      "Valid rows   : 55543\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "files = {\n",
    "    \"all\" : \"/kaggle/working/train_data/all_pairs.txt\",\n",
    "    \"train\": \"/kaggle/working/train_data/train_pairs.txt\",\n",
    "    \"val\": \"/kaggle/working/train_data/val_pairs.txt\",\n",
    "}\n",
    "\n",
    "def check_file(file_path):\n",
    "    total = 0\n",
    "    bad = 0\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line_num, line in enumerate(f, start=1):\n",
    "            total += 1\n",
    "            parts = line.strip().split()\n",
    "\n",
    "            # 1) Less than 5 columns\n",
    "            if len(parts) < 5:\n",
    "                bad += 1\n",
    "                continue\n",
    "\n",
    "            # 2) Literal 'nan' or empty string in ANY column\n",
    "            if any(p.strip() == \"\" or p.lower() == \"nan\" for p in parts):\n",
    "                bad += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 3) Numeric checks (last 3 columns)\n",
    "                nums = [float(parts[2]), float(parts[3]), float(parts[4])]\n",
    "\n",
    "                # 4) Actual NaN values\n",
    "                if any(math.isnan(x) for x in nums):\n",
    "                    bad += 1\n",
    "\n",
    "            except ValueError:\n",
    "                # Non-numeric values\n",
    "                bad += 1\n",
    "\n",
    "    return total, bad\n",
    "\n",
    "\n",
    "# Run checks\n",
    "for name, path in files.items():\n",
    "    total, bad = check_file(path)\n",
    "    print(f\"\\nüìÇ {name.upper()} FILE\")\n",
    "    print(f\"Total rows   : {total}\")\n",
    "    print(f\"Invalid rows : {bad}\")\n",
    "    print(f\"Valid rows   : {total - bad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03a4fd2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:47.892034Z",
     "iopub.status.busy": "2025-12-24T20:08:47.891813Z",
     "iopub.status.idle": "2025-12-24T20:08:49.379866Z",
     "shell.execute_reply": "2025-12-24T20:08:49.378816Z"
    },
    "papermill": {
     "duration": 1.496339,
     "end_time": "2025-12-24T20:08:49.381463",
     "exception": false,
     "start_time": "2025-12-24T20:08:47.885124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ ALL FILE CLEANED\n",
      "Original rows : 277828\n",
      "Kept rows     : 277707\n",
      "Dropped rows  : 121\n",
      "\n",
      "üìÇ TRAIN FILE CLEANED\n",
      "Original rows : 222262\n",
      "Kept rows     : 222164\n",
      "Dropped rows  : 98\n",
      "\n",
      "üìÇ VAL FILE CLEANED\n",
      "Original rows : 55566\n",
      "Kept rows     : 55543\n",
      "Dropped rows  : 23\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "files = {\n",
    "    \"all\"  : \"/kaggle/working/train_data/all_pairs.txt\",\n",
    "    \"train\": \"/kaggle/working/train_data/train_pairs.txt\",\n",
    "    \"val\"  : \"/kaggle/working/train_data/val_pairs.txt\",\n",
    "}\n",
    "\n",
    "def is_valid_row(parts):\n",
    "    # Less than 5 columns\n",
    "    if len(parts) < 5:\n",
    "        return False\n",
    "\n",
    "    # Literal 'nan' or empty string anywhere\n",
    "    if any(p.strip() == \"\" or p.lower() == \"nan\" for p in parts):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        nums = [float(parts[2]), float(parts[3]), float(parts[4])]\n",
    "        if any(math.isnan(x) for x in nums):\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "for name, path in files.items():\n",
    "    temp_path = path + \".tmp\"\n",
    "\n",
    "    total = 0\n",
    "    kept = 0\n",
    "\n",
    "    with open(path, \"r\") as fin, open(temp_path, \"w\") as fout:\n",
    "        for line in fin:\n",
    "            total += 1\n",
    "            parts = line.strip().split()\n",
    "\n",
    "            if is_valid_row(parts):\n",
    "                fout.write(line)\n",
    "                kept += 1\n",
    "\n",
    "    # Replace original file safely\n",
    "    shutil.move(temp_path, path)\n",
    "\n",
    "    print(f\"\\nüìÇ {name.upper()} FILE CLEANED\")\n",
    "    print(f\"Original rows : {total}\")\n",
    "    print(f\"Kept rows     : {kept}\")\n",
    "    print(f\"Dropped rows  : {total - kept}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd814fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:49.395040Z",
     "iopub.status.busy": "2025-12-24T20:08:49.394478Z",
     "iopub.status.idle": "2025-12-24T20:08:50.528893Z",
     "shell.execute_reply": "2025-12-24T20:08:50.528205Z"
    },
    "papermill": {
     "duration": 1.142949,
     "end_time": "2025-12-24T20:08:50.530631",
     "exception": false,
     "start_time": "2025-12-24T20:08:49.387682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AQUAFace'...\r\n",
      "remote: Enumerating objects: 77, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (77/77), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (69/69), done.\u001b[K\r\n",
      "remote: Total 77 (delta 2), reused 73 (delta 2), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (77/77), 3.66 MiB | 36.00 MiB/s, done.\r\n",
      "Resolving deltas: 100% (2/2), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AbdoTW/AQUAFace.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19eea019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:50.544565Z",
     "iopub.status.busy": "2025-12-24T20:08:50.544302Z",
     "iopub.status.idle": "2025-12-24T20:08:57.441824Z",
     "shell.execute_reply": "2025-12-24T20:08:57.440896Z"
    },
    "papermill": {
     "duration": 6.906372,
     "end_time": "2025-12-24T20:08:57.443571",
     "exception": false,
     "start_time": "2025-12-24T20:08:50.537199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1dWZb0SLcdzr-toUzsVZ1zogn9dEIW1Dk\r\n",
      "To: /kaggle/working/R18_MS1MV3.onnx\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96.1M/96.1M [00:01<00:00, 69.0MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1dWZb0SLcdzr-toUzsVZ1zogn9dEIW1Dk -O R18_MS1MV3.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d2be76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:08:57.458438Z",
     "iopub.status.busy": "2025-12-24T20:08:57.457930Z",
     "iopub.status.idle": "2025-12-24T20:09:02.233369Z",
     "shell.execute_reply": "2025-12-24T20:09:02.232469Z"
    },
    "papermill": {
     "duration": 4.784464,
     "end_time": "2025-12-24T20:09:02.234975",
     "exception": false,
     "start_time": "2025-12-24T20:08:57.450511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From (original): https://drive.google.com/uc?id=1Gh8C-bwl2B90RDrvKJkXafvZC3q4_H_z\r\n",
      "From (redirected): https://drive.google.com/uc?id=1Gh8C-bwl2B90RDrvKJkXafvZC3q4_H_z&confirm=t&uuid=4f866ca7-c0c2-464f-aba4-95be61aa43d1\r\n",
      "To: /kaggle/working/R100_Glint360K.onnx\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 261M/261M [00:02<00:00, 115MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1Gh8C-bwl2B90RDrvKJkXafvZC3q4_H_z -O R100_Glint360K.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6c7cb9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:02.251238Z",
     "iopub.status.busy": "2025-12-24T20:09:02.250954Z",
     "iopub.status.idle": "2025-12-24T20:09:02.712745Z",
     "shell.execute_reply": "2025-12-24T20:09:02.712051Z"
    },
    "papermill": {
     "duration": 0.471751,
     "end_time": "2025-12-24T20:09:02.714332",
     "exception": false,
     "start_time": "2025-12-24T20:09:02.242581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R100_Glint360K.onnx  R18_MS1MV3.onnx\r\n"
     ]
    }
   ],
   "source": [
    "# Create the folder\n",
    "!mkdir -p /kaggle/working/AQUAFace/pretrained_models\n",
    "\n",
    "# Move the ONNX models into it\n",
    "!mv /kaggle/working/R100_Glint360K.onnx /kaggle/working/AQUAFace/pretrained_models/\n",
    "!mv /kaggle/working/R18_MS1MV3.onnx /kaggle/working/AQUAFace/pretrained_models/\n",
    "\n",
    "!ls /kaggle/working/AQUAFace/pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a82b4fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:02.730639Z",
     "iopub.status.busy": "2025-12-24T20:09:02.730069Z",
     "iopub.status.idle": "2025-12-24T20:09:02.733528Z",
     "shell.execute_reply": "2025-12-24T20:09:02.732973Z"
    },
    "papermill": {
     "duration": 0.013068,
     "end_time": "2025-12-24T20:09:02.734882",
     "exception": false,
     "start_time": "2025-12-24T20:09:02.721814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -f /kaggle/working/AQUAFace/train_data/all_pairs.txt\n",
    "# !rm -f /kaggle/working/AQUAFace/train_data/train_pairs.txt\n",
    "# !rm -f /kaggle/working/AQUAFace/train_data/val_pairs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "365d6034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:02.750425Z",
     "iopub.status.busy": "2025-12-24T20:09:02.749985Z",
     "iopub.status.idle": "2025-12-24T20:09:03.134329Z",
     "shell.execute_reply": "2025-12-24T20:09:03.133572Z"
    },
    "papermill": {
     "duration": 0.393979,
     "end_time": "2025-12-24T20:09:03.136059",
     "exception": false,
     "start_time": "2025-12-24T20:09:02.742080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/working/train_data/all_pairs.txt /kaggle/working/AQUAFace/train_data/\n",
    "!cp /kaggle/working/train_data/train_pairs.txt /kaggle/working/AQUAFace/train_data/\n",
    "!cp /kaggle/working/train_data/val_pairs.txt /kaggle/working/AQUAFace/train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77251116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:03.152707Z",
     "iopub.status.busy": "2025-12-24T20:09:03.151950Z",
     "iopub.status.idle": "2025-12-24T20:09:03.489679Z",
     "shell.execute_reply": "2025-12-24T20:09:03.488785Z"
    },
    "papermill": {
     "duration": 0.347411,
     "end_time": "2025-12-24T20:09:03.491127",
     "exception": false,
     "start_time": "2025-12-24T20:09:03.143716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All rows have exactly 5 values. File is CLEAN!\n",
      "\n",
      "‚úÖ Total checked rows: 277707\n",
      "‚ùå Total bad rows: 0\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/working/AQUAFace/train_data/all_pairs.txt\"\n",
    "\n",
    "bad_rows = []\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line_num, line in enumerate(f, start=1):\n",
    "        line = line.strip()\n",
    "\n",
    "        # Skip empty lines safely\n",
    "        if not line:\n",
    "            bad_rows.append((line_num, 0, \"EMPTY LINE\"))\n",
    "            continue\n",
    "\n",
    "        values = line.split()  # split on spaces\n",
    "        num_values = len(values)\n",
    "\n",
    "        if num_values != 5:\n",
    "            bad_rows.append((line_num, num_values, line))\n",
    "\n",
    "# ---------- REPORT ----------\n",
    "if bad_rows:\n",
    "    print(f\"\\n‚ùå Found {len(bad_rows)} bad rows:\\n\")\n",
    "    # for row in bad_rows:\n",
    "    #     print(f\"Line {row[0]} -> {row[1]} values:\")\n",
    "    #     print(row[2])\n",
    "    #     print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All rows have exactly 5 values. File is CLEAN!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total checked rows: {line_num}\")\n",
    "print(f\"‚ùå Total bad rows: {len(bad_rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "804cef7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:03.507427Z",
     "iopub.status.busy": "2025-12-24T20:09:03.507121Z",
     "iopub.status.idle": "2025-12-24T20:09:03.521471Z",
     "shell.execute_reply": "2025-12-24T20:09:03.520792Z"
    },
    "papermill": {
     "duration": 0.024179,
     "end_time": "2025-12-24T20:09:03.522923",
     "exception": false,
     "start_time": "2025-12-24T20:09:03.498744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' > /kaggle/working/AQUAFace/config/config.py\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        test_model_path='checkpoints/resnet18_110.pth',\n",
    "        lfw_test_list=None\n",
    "    ):\n",
    "        # =====================================================\n",
    "        # Base directory (AQUAFace root)\n",
    "        # =====================================================\n",
    "        self.base_dir = os.path.abspath(\n",
    "            os.path.join(os.path.dirname(__file__), '..')\n",
    "        )\n",
    "        \n",
    "        self.env = 'kaggle'  # Environment identifier\n",
    "        self.backbone = 'r100'  \n",
    "        self.classify = 'softmax'\n",
    "        \n",
    "        # ===== Auto-calculate num_classes from metadata =====\n",
    "        metadata_path = '/kaggle/working/morph_cacd_agedb_fgnet_clean.csv'\n",
    "        if os.path.exists(metadata_path):\n",
    "            df = pd.read_csv(metadata_path)\n",
    "            self.num_classes = len(df['identity'].unique())\n",
    "            print(f\"Auto-detected num_classes: {self.num_classes}\")\n",
    "        else:\n",
    "            # Fallback if file doesn't exist\n",
    "            self.num_classes = 19385\n",
    "            print(f\"Warning: Metadata file not found, using default num_classes: {self.num_classes}\")\n",
    "        \n",
    "        self.metric = 'arc_margin'\n",
    "        self.easy_margin = False\n",
    "        self.use_se = True\n",
    "        self.loss = 'con_loss'\n",
    "        \n",
    "        self.display = False\n",
    "        self.finetune = True  # We're fine-tuning pretrained model\n",
    "        \n",
    "        # =====================================================\n",
    "        # Training data paths\n",
    "        # =====================================================\n",
    "        self.train_root = os.path.join(self.base_dir, 'dataset', 'AgeDB')\n",
    "        self.train_list = os.path.join(self.base_dir, 'train_data', 'train_pairs.txt')\n",
    "        self.val_list = os.path.join(self.base_dir, 'train_data', 'val_pairs.txt')\n",
    "        \n",
    "        # Test data\n",
    "        self.test_root = os.path.join(self.base_dir, 'dataset', 'AgeDB')\n",
    "        self.test_list = os.path.join(self.base_dir, 'test.txt')\n",
    "        \n",
    "        # LFW (disabled on Kaggle)\n",
    "        self.lfw_root = None\n",
    "        self.lfw_test_list = lfw_test_list\n",
    "        \n",
    "        # =====================================================\n",
    "        # Checkpoints & pretrained models\n",
    "        # =====================================================\n",
    "        self.checkpoints_path = os.path.join(self.base_dir, 'checkpoints')\n",
    "        \n",
    "        # Pretrained model path\n",
    "        self.load_model_path = os.path.join(\n",
    "            self.base_dir,\n",
    "            'pretrained_models',\n",
    "            'R100_Glint360K.onnx'\n",
    "        )\n",
    "        \n",
    "        self.test_model_path = test_model_path\n",
    "        self.save_interval = 1  # Save every epoch\n",
    "        \n",
    "        # =====================================================\n",
    "        # OPTIMIZED FOR KAGGLE 16GB GPU\n",
    "        # =====================================================\n",
    "        self.train_batch_size = 128  # Reduced from 512 for stability\n",
    "        self.test_batch_size = 128\n",
    "        \n",
    "        self.input_shape = (1, 112, 112)  # Standard for face recognition models\n",
    "        self.optimizer = 'adam'  # Use adam like the old code\n",
    "        \n",
    "        self.lr = 2e-3  # Learning rate for Adam optimizer (matching old code)\n",
    "        self.lr_step = 10\n",
    "        self.lr_decay = 0.95\n",
    "        self.weight_decay = 5e-4\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "        self.max_epoch = 15  # Reduced for Kaggle\n",
    "        \n",
    "        self.num_workers = 2  # Kaggle-friendly\n",
    "        self.pin_memory = True\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70e62e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:03.539226Z",
     "iopub.status.busy": "2025-12-24T20:09:03.538875Z",
     "iopub.status.idle": "2025-12-24T20:09:03.578771Z",
     "shell.execute_reply": "2025-12-24T20:09:03.578287Z"
    },
    "papermill": {
     "duration": 0.049941,
     "end_time": "2025-12-24T20:09:03.580137",
     "exception": false,
     "start_time": "2025-12-24T20:09:03.530196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' > /kaggle/working/AQUAFace/train.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "from models import get_model\n",
    "from loss.focal import *\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "from models import *\n",
    "from models import metrics\n",
    "from utils.visualizer import *\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(16)\n",
    "import time\n",
    "from config.config import *\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from torch.nn import DataParallel\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hmean\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from accelerate import Accelerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "torch.manual_seed(16)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =====================================================\n",
    "# LOAD METADATA AND CREATE LOOKUP DICTIONARY\n",
    "# =====================================================\n",
    "METADATA_PATH = '/kaggle/working/morph_cacd_agedb_fgnet_clean.csv'\n",
    "print(\"Loading metadata...\")\n",
    "metadata_df = pd.read_csv(METADATA_PATH)\n",
    "print(f\"Loaded {len(metadata_df)} rows from metadata\")\n",
    "\n",
    "# Create fast lookup dictionary\n",
    "metadata_lookup = {\n",
    "    row['filepath']: {\n",
    "        'identity': row['identity'],\n",
    "        'age': row['age'],\n",
    "        'gender': row['gender']\n",
    "    }\n",
    "    for _, row in metadata_df.iterrows()\n",
    "}\n",
    "print(f\"Created lookup dictionary with {len(metadata_lookup)} entries\")\n",
    "\n",
    "# Create subject ID mapping from unique identities\n",
    "unique_identities = sorted(metadata_df['identity'].unique())\n",
    "subject_id_map = {identity: idx for idx, identity in enumerate(unique_identities)}\n",
    "print(f\"Created subject_id_map with {len(subject_id_map)} unique identities\")\n",
    "\n",
    "\n",
    "class FixedDropout(torch.nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(FixedDropout, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.dropout(x, p=self.p, training=self.training)\n",
    "\n",
    "\n",
    "def save_model(model, save_path, name, iter_cnt, best_metric, current_metric, metric_name=\"loss\"):\n",
    "    \"\"\"Save model checkpoint if metric improves\"\"\"\n",
    "    save_name = os.path.join(save_path, name + '_' + str(iter_cnt) + '.pth')\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    print(f'Best {metric_name}: {best_metric:.4f}, Current {metric_name}: {current_metric:.4f}')\n",
    "    \n",
    "    # For loss: lower is better, for accuracy/AUC: higher is better\n",
    "    if metric_name == \"loss\":\n",
    "        improved = current_metric < best_metric\n",
    "    else:  # accuracy, AUC, etc.\n",
    "        improved = current_metric > best_metric\n",
    "    \n",
    "    if improved:\n",
    "        print(f'Saving checkpoint to {save_name}')\n",
    "        torch.save({\n",
    "            'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
    "            'epoch': iter_cnt,\n",
    "            metric_name: current_metric\n",
    "        }, save_name)\n",
    "        return current_metric\n",
    "    else:\n",
    "        print('Metric did not improve, not saving')\n",
    "        return best_metric\n",
    "\n",
    "\n",
    "class FDataset(Dataset):\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # Use the global subject_id_map (already created from metadata)\n",
    "        self.subject_id_map = subject_id_map\n",
    "        print(f\"FDataset initialized with {len(self.data)} samples\")\n",
    "        print(f\"Using subject_id_map with {len(self.subject_id_map)} unique identities\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_metadata(self, filepath):\n",
    "        \"\"\"Get identity, age, gender from metadata lookup\"\"\"\n",
    "        metadata = metadata_lookup.get(filepath)\n",
    "        if metadata is None:\n",
    "            raise ValueError(f\"Filepath not found in metadata: {filepath}\")\n",
    "        return metadata['identity'], metadata['age'], metadata['gender']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            sample = self.data[index]\n",
    "            splits = sample.strip().split()\n",
    "            \n",
    "            # Parse the pair information\n",
    "            img1_path = splits[0].strip()\n",
    "            img2_path = splits[1].strip()\n",
    "            same_person = int(splits[2])\n",
    "            same_age_group = int(splits[3])\n",
    "            age_gap = float(splits[4])\n",
    "            \n",
    "            # Get metadata for both images\n",
    "            identity1, age1, gender1 = self.get_metadata(img1_path)\n",
    "            identity2, age2, gender2 = self.get_metadata(img2_path)\n",
    "            \n",
    "            # Get subject IDs\n",
    "            subject_id1 = self.subject_id_map[identity1]\n",
    "            subject_id2 = self.subject_id_map[identity2]\n",
    "            \n",
    "            # Load images\n",
    "            img1 = Image.open(img1_path).convert('RGB')\n",
    "            img2 = Image.open(img2_path).convert('RGB')\n",
    "            \n",
    "            if self.transforms is not None:\n",
    "                img1 = self.transforms(img1)\n",
    "                img2 = self.transforms(img2)\n",
    "            \n",
    "            return {\n",
    "                'img1': img1,\n",
    "                'img2': img2,\n",
    "                'same_person': same_person,\n",
    "                'same_age_group': same_age_group,\n",
    "                'age_gap': age_gap,\n",
    "                'subject_id1': subject_id1,\n",
    "                'subject_id2': subject_id2,\n",
    "                'age1': age1,\n",
    "                'age2': age2\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample at index {index}: {sample}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load pairs from text file\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        pairs = f.readlines()\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_metrics(embedding1, embedding2, same_person, same_age_group, age_gaps):\n",
    "    \"\"\"Calculate metrics\"\"\"\n",
    "    # Cosine similarity\n",
    "    cos_sim = F.cosine_similarity(embedding1, embedding2)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    cos_sim_np = cos_sim.detach().cpu().numpy()\n",
    "    same_person_np = same_person.cpu().numpy()\n",
    "    same_age_group_np = same_age_group.cpu().numpy()\n",
    "    age_gaps_np = age_gaps.cpu().numpy()\n",
    "    \n",
    "    # Person verification AUC\n",
    "    person_auc = roc_auc_score(same_person_np, cos_sim_np)\n",
    "    \n",
    "    # Age group AUC\n",
    "    age_group_auc = roc_auc_score(same_age_group_np, cos_sim_np)\n",
    "    \n",
    "    # Calculate best threshold for person verification\n",
    "    fpr, tpr, thresholds = roc_curve(same_person_np, cos_sim_np)\n",
    "    best_threshold_idx = np.argmax(tpr - fpr)\n",
    "    best_threshold = thresholds[best_threshold_idx]\n",
    "    \n",
    "    # Accuracy at best threshold\n",
    "    predictions = (cos_sim_np >= best_threshold).astype(int)\n",
    "    accuracy = accuracy_score(same_person_np, predictions)\n",
    "    \n",
    "    return {\n",
    "        'person_auc': person_auc,\n",
    "        'age_group_auc': age_group_auc,\n",
    "        'accuracy': accuracy,\n",
    "        'best_threshold': best_threshold\n",
    "    }\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, accelerator, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_cos_sim = []\n",
    "    all_same_person = []\n",
    "    all_same_age_group = []\n",
    "    all_age_gaps = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        img1 = batch['img1']\n",
    "        img2 = batch['img2']\n",
    "        same_person = batch['same_person']\n",
    "        same_age_group = batch['same_age_group']\n",
    "        age_gap = batch['age_gap']\n",
    "        subject_id1 = batch['subject_id1']\n",
    "        subject_id2 = batch['subject_id2']\n",
    "        \n",
    "        # Get embeddings\n",
    "        embedding1 = model(img1)\n",
    "        embedding2 = model(img2)\n",
    "        \n",
    "        # Apply metric learning through the attached metric_fc\n",
    "        output1 = model.module.metric_fc(embedding1, subject_id1)\n",
    "        output2 = model.module.metric_fc(embedding2, subject_id2)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss1 = criterion(output1, subject_id1)\n",
    "        loss2 = criterion(output2, subject_id2)\n",
    "        loss = (loss1 + loss2) / 2\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cos_sim = F.cosine_similarity(embedding1, embedding2)\n",
    "            all_cos_sim.append(cos_sim.cpu())\n",
    "            all_same_person.append(same_person.cpu())\n",
    "            all_same_age_group.append(same_age_group.cpu())\n",
    "            all_age_gaps.append(age_gap.cpu())\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    all_cos_sim = torch.cat(all_cos_sim).numpy()\n",
    "    all_same_person = torch.cat(all_same_person).numpy()\n",
    "    all_same_age_group = torch.cat(all_same_age_group).numpy()\n",
    "    all_age_gaps = torch.cat(all_age_gaps).numpy()\n",
    "    \n",
    "    # Calculate person AUC\n",
    "    try:\n",
    "        person_auc = roc_auc_score(all_same_person, all_cos_sim)\n",
    "    except ValueError:\n",
    "        person_auc = 0.0\n",
    "        print(\"Warning: Could not calculate person AUC (only one class present)\")\n",
    "    \n",
    "    # Calculate age group AUC\n",
    "    try:\n",
    "        age_group_auc = roc_auc_score(all_same_age_group, all_cos_sim)\n",
    "    except ValueError:\n",
    "        age_group_auc = 0.0\n",
    "        print(\"Warning: Could not calculate age group AUC (only one class present)\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(all_same_person, all_cos_sim)\n",
    "        best_threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "        accuracy = accuracy_score(all_same_person, (all_cos_sim >= best_threshold).astype(int))\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate accuracy: {e}\")\n",
    "        accuracy = 0.0\n",
    "        best_threshold = 0.5\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'person_auc': person_auc,\n",
    "        'age_group_auc': age_group_auc,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, accelerator):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_cos_sim = []\n",
    "    all_same_person = []\n",
    "    all_same_age_group = []\n",
    "    all_age_gaps = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=\"Validation\")\n",
    "        for batch in pbar:\n",
    "            img1 = batch['img1']\n",
    "            img2 = batch['img2']\n",
    "            same_person = batch['same_person']\n",
    "            same_age_group = batch['same_age_group']\n",
    "            age_gap = batch['age_gap']\n",
    "            subject_id1 = batch['subject_id1']\n",
    "            subject_id2 = batch['subject_id2']\n",
    "            \n",
    "            # Get embeddings\n",
    "            embedding1 = model(img1)\n",
    "            embedding2 = model(img2)\n",
    "            \n",
    "            # Apply metric learning\n",
    "            output1 = model.module.metric_fc(embedding1, subject_id1)\n",
    "            output2 = model.module.metric_fc(embedding2, subject_id2)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss1 = criterion(output1, subject_id1)\n",
    "            loss2 = criterion(output2, subject_id2)\n",
    "            loss = (loss1 + loss2) / 2\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            cos_sim = F.cosine_similarity(embedding1, embedding2)\n",
    "            all_cos_sim.append(cos_sim.cpu())\n",
    "            all_same_person.append(same_person.cpu())\n",
    "            all_same_age_group.append(same_age_group.cpu())\n",
    "            all_age_gaps.append(age_gap.cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    all_cos_sim = torch.cat(all_cos_sim).numpy()\n",
    "    all_same_person = torch.cat(all_same_person).numpy()\n",
    "    all_same_age_group = torch.cat(all_same_age_group).numpy()\n",
    "    all_age_gaps = torch.cat(all_age_gaps).numpy()\n",
    "    \n",
    "    # Calculate person AUC\n",
    "    try:\n",
    "        person_auc = roc_auc_score(all_same_person, all_cos_sim)\n",
    "    except ValueError:\n",
    "        person_auc = 0.0\n",
    "        print(\"Warning: Could not calculate person AUC (only one class present)\")\n",
    "    \n",
    "    # Calculate age group AUC\n",
    "    try:\n",
    "        age_group_auc = roc_auc_score(all_same_age_group, all_cos_sim)\n",
    "    except ValueError:\n",
    "        age_group_auc = 0.0\n",
    "        print(\"Warning: Could not calculate age group AUC (only one class present)\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(all_same_person, all_cos_sim)\n",
    "        best_threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "        accuracy = accuracy_score(all_same_person, (all_cos_sim >= best_threshold).astype(int))\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate accuracy: {e}\")\n",
    "        accuracy = 0.0\n",
    "        best_threshold = 0.5\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'person_auc': person_auc,\n",
    "        'age_group_auc': age_group_auc,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_base_model(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate base model before training.\n",
    "    Returns metrics: ROC AUC, Accuracy, TPR@FPR\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üîç EVALUATING BASE MODEL (BEFORE TRAINING)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    similarities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validating Base Model\"):\n",
    "            img1 = batch['img1'].to(device)\n",
    "            img2 = batch['img2'].to(device)\n",
    "            same_person = batch['same_person']\n",
    "            \n",
    "            # Get embeddings\n",
    "            feature1 = model(img1)\n",
    "            feature2 = model(img2)\n",
    "            \n",
    "            # Compute cosine similarity\n",
    "            feature1_np = feature1.data.cpu().numpy()\n",
    "            feature2_np = feature2.data.cpu().numpy()\n",
    "            \n",
    "            for i in range(feature1_np.shape[0]):\n",
    "                sim = 1 - spatial.distance.cosine(feature1_np[i].flatten(), feature2_np[i].flatten())\n",
    "                if sim < 0:\n",
    "                    sim = 0.0\n",
    "                similarities.append(sim)\n",
    "                y_true.append(same_person[i].item())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    similarities = np.array(similarities)\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, similarities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_accuracy = np.mean((similarities >= optimal_threshold) == y_true)\n",
    "    \n",
    "    # TPR at fixed FPR values\n",
    "    tpr_at_fpr = {}\n",
    "    for fpr_value in [0.0001, 0.001, 0.01, 0.1]:\n",
    "        idx = np.where(fpr >= fpr_value)[0]\n",
    "        if len(idx) > 0:\n",
    "            tpr_at_fpr[fpr_value] = tpr[idx[0]]\n",
    "        else:\n",
    "            tpr_at_fpr[fpr_value] = 0.0\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüéØ Validation Results:\")\n",
    "    print(f\"  Validation pairs: {len(y_true)}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"  Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "    print(f\"  Accuracy at Optimal Threshold: {optimal_accuracy:.4f}\")\n",
    "    print(f\"  TPR at FPR=0.01%: {tpr_at_fpr.get(0.0001, 0):.4f}\")\n",
    "    print(f\"  TPR at FPR=0.1%:  {tpr_at_fpr.get(0.001, 0):.4f}\")\n",
    "    print(f\"  TPR at FPR=1%:    {tpr_at_fpr.get(0.01, 0):.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(\"\\nüìä BASE MODEL PERFORMANCE:\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"  Accuracy: {optimal_accuracy:.4f}\")\n",
    "    print(f\"  TPR@FPR=0.01%: {tpr_at_fpr.get(0.0001, 0):.4f}\")\n",
    "    print(f\"  TPR@FPR=1%: {tpr_at_fpr.get(0.01, 0):.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ NOW STARTING TRAINING...\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'accuracy': optimal_accuracy,\n",
    "        'threshold': optimal_threshold,\n",
    "        'tpr_at_fpr': tpr_at_fpr\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize config and accelerator\n",
    "    opt = Config()\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    print(f\"Accelerator device: {accelerator.device}\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Kaggle Configuration Loaded\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Batch Size (Train): {opt.train_batch_size}\")\n",
    "    print(f\"Batch Size (Test):  {opt.test_batch_size}\")\n",
    "    print(f\"Max Epochs:         {opt.max_epoch}\")\n",
    "    print(f\"Num Classes:        {opt.num_classes}\")\n",
    "    print(f\"Num Workers:        {opt.num_workers}\")\n",
    "    print(f\"Pretrained Model:   {os.path.basename(opt.load_model_path)}\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),  # Standard size for face recognition\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # Load training data\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Loading Training Data (MORPH + AgeDB + CACD + FGNET)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    train_pairs_file = '/kaggle/working/train_data/train_pairs.txt'\n",
    "    val_pairs_file = '/kaggle/working/train_data/val_pairs.txt'\n",
    "    \n",
    "    print(f\"USING TRAIN LIST FILE: {train_pairs_file}\")\n",
    "    \n",
    "    # Load pairs\n",
    "    all_pairs = load_data(train_pairs_file)\n",
    "    print(f\"Total train pairs loaded: {len(all_pairs)}\")\n",
    "    \n",
    "    val_pairs = load_data(val_pairs_file)\n",
    "    print(f\"Total val pairs loaded: {len(val_pairs)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = FDataset(data=all_pairs, transforms=transform)\n",
    "    val_dataset = FDataset(data=val_pairs, transforms=transform)\n",
    "    \n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "    print()\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=opt.train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=opt.num_workers,\n",
    "        pin_memory=opt.pin_memory\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=opt.test_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=opt.num_workers,\n",
    "        pin_memory=opt.pin_memory\n",
    "    )\n",
    "    \n",
    "    # Initialize model - Load ONNX pretrained model\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Loading Pretrained Model\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        import onnx\n",
    "        from onnx2pytorch import ConvertModel\n",
    "        \n",
    "        onnx_path = opt.load_model_path\n",
    "        print(f\"Loading ONNX model from: {onnx_path}\")\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        model = ConvertModel(onnx_model)\n",
    "        print(\"‚úÖ ONNX model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load pretrained ONNX model: {e}\")\n",
    "        print(\"Please install: pip install onnx onnx2pytorch\")\n",
    "        raise\n",
    "    \n",
    "    # Metric learning head\n",
    "    if opt.metric == 'add_margin':\n",
    "        metric_fc = metrics.AddMarginProduct(512, opt.num_classes, s=30, m=0.35)\n",
    "    elif opt.metric == 'arc_margin':\n",
    "        metric_fc = metrics.ArcMarginProduct(512, opt.num_classes, s=30, m=0.5, easy_margin=opt.easy_margin)\n",
    "    elif opt.metric == 'sphere':\n",
    "        metric_fc = metrics.SphereProduct(512, opt.num_classes, m=4)\n",
    "    else:\n",
    "        metric_fc = torch.nn.Linear(512, opt.num_classes)\n",
    "    \n",
    "    # Wrap model with DataParallel and attach metric_fc\n",
    "    model = DataParallel(model).to(device)\n",
    "    metric_fc = metric_fc.to(device)\n",
    "    model.module.metric_fc = metric_fc\n",
    "    \n",
    "    print(f\"Model: {opt.backbone}\")\n",
    "    print(f\"Metric FC: {opt.metric}\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # ===== EVALUATE BASE MODEL BEFORE TRAINING =====\n",
    "    base_results = evaluate_base_model(model, val_loader, device)\n",
    "    \n",
    "    # ===== FREEZE BACKBONE LAYERS (Fine-tuning strategy) =====\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Freezing Backbone - Fine-tuning Strategy\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        # Only train: bn4, fc5, bn5, and metric_fc\n",
    "        if 'bn4' not in name and 'fc5' not in name and 'bn5' not in name and 'metric_fc' not in name:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    print(\"Trainable parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"  {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    if opt.optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=opt.lr,\n",
    "            momentum=opt.momentum,\n",
    "            weight_decay=opt.weight_decay\n",
    "        )\n",
    "    else:  # adam\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=opt.lr,\n",
    "            weight_decay=opt.weight_decay\n",
    "        )\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=opt.lr_step, gamma=opt.lr_decay)\n",
    "    \n",
    "    # Prepare with accelerator\n",
    "    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader, scheduler\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Optimizer: {opt.optimizer}\")\n",
    "    print(f\"Learning rate: {opt.lr}\")\n",
    "    print(f\"Loss function: CrossEntropyLoss\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_auc = base_results['roc_auc'] if base_results else 0.0  # Initialize with base model AUC\n",
    "    \n",
    "    for epoch in range(1, opt.max_epoch + 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch}/{opt.max_epoch}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_one_epoch(model, train_loader, criterion, optimizer, accelerator, epoch)\n",
    "        \n",
    "        print(f\"\\nTrain Metrics:\")\n",
    "        print(f\"  Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"  Person AUC: {train_metrics['person_auc']:.4f}\")\n",
    "        print(f\"  Age Group AUC: {train_metrics['age_group_auc']:.4f}\")\n",
    "        print(f\"  Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics = validate(model, val_loader, criterion, accelerator)\n",
    "        \n",
    "        print(f\"\\nValidation Metrics:\")\n",
    "        print(f\"  Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"  Person AUC: {val_metrics['person_auc']:.4f}\")\n",
    "        print(f\"  Age Group AUC: {val_metrics['age_group_auc']:.4f}\")\n",
    "        print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # Step scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save model\n",
    "        if epoch % opt.save_interval == 0:\n",
    "            best_val_auc = save_model(\n",
    "                model,\n",
    "                opt.checkpoints_path,\n",
    "                opt.backbone,\n",
    "                epoch,\n",
    "                best_val_auc,\n",
    "                val_metrics['person_auc'],\n",
    "                metric_name=\"person_auc\"\n",
    "            )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48034b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:03.596074Z",
     "iopub.status.busy": "2025-12-24T20:09:03.595853Z",
     "iopub.status.idle": "2025-12-24T20:09:03.600634Z",
     "shell.execute_reply": "2025-12-24T20:09:03.599923Z"
    },
    "papermill": {
     "duration": 0.01422,
     "end_time": "2025-12-24T20:09:03.601943",
     "exception": false,
     "start_time": "2025-12-24T20:09:03.587723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/AQUAFace\n"
     ]
    }
   ],
   "source": [
    "cd AQUAFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82d5fa19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:03.619183Z",
     "iopub.status.busy": "2025-12-24T20:09:03.618664Z",
     "iopub.status.idle": "2025-12-24T20:09:16.965256Z",
     "shell.execute_reply": "2025-12-24T20:09:16.964505Z"
    },
    "papermill": {
     "duration": 13.357835,
     "end_time": "2025-12-24T20:09:16.967098",
     "exception": false,
     "start_time": "2025-12-24T20:09:03.609263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbc57823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:16.984481Z",
     "iopub.status.busy": "2025-12-24T20:09:16.984120Z",
     "iopub.status.idle": "2025-12-24T20:09:16.987825Z",
     "shell.execute_reply": "2025-12-24T20:09:16.987127Z"
    },
    "papermill": {
     "duration": 0.014119,
     "end_time": "2025-12-24T20:09:16.989196",
     "exception": false,
     "start_time": "2025-12-24T20:09:16.975077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cat /kaggle/working/AQUAFace/models/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df36e66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:09:17.005289Z",
     "iopub.status.busy": "2025-12-24T20:09:17.005042Z",
     "iopub.status.idle": "2025-12-25T01:36:54.836567Z",
     "shell.execute_reply": "2025-12-25T01:36:54.835595Z"
    },
    "papermill": {
     "duration": 19657.841674,
     "end_time": "2025-12-25T01:36:54.838375",
     "exception": false,
     "start_time": "2025-12-24T20:09:16.996701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\r\n",
      "Loading metadata...\r\n",
      "Loaded 174014 rows from metadata\r\n",
      "Created lookup dictionary with 174014 entries\r\n",
      "Created subject_id_map with 3236 unique identities\r\n",
      "Auto-detected num_classes: 3236\r\n",
      "Accelerator device: cuda\r\n",
      "\r\n",
      "============================================================\r\n",
      "Kaggle Configuration Loaded\r\n",
      "============================================================\r\n",
      "Batch Size (Train): 128\r\n",
      "Batch Size (Test):  128\r\n",
      "Max Epochs:         15\r\n",
      "Num Classes:        3236\r\n",
      "Num Workers:        2\r\n",
      "Pretrained Model:   R100_Glint360K.onnx\r\n",
      "============================================================\r\n",
      "\r\n",
      "============================================================\r\n",
      "Loading Training Data (MORPH + AgeDB + CACD + FGNET)\r\n",
      "============================================================\r\n",
      "USING TRAIN LIST FILE: /kaggle/working/train_data/train_pairs.txt\r\n",
      "Total train pairs loaded: 222164\r\n",
      "Total val pairs loaded: 55543\r\n",
      "FDataset initialized with 222164 samples\r\n",
      "Using subject_id_map with 3236 unique identities\r\n",
      "FDataset initialized with 55543 samples\r\n",
      "Using subject_id_map with 3236 unique identities\r\n",
      "Train dataset size: 222164\r\n",
      "Val dataset size: 55543\r\n",
      "\r\n",
      "============================================================\r\n",
      "Loading Pretrained Model\r\n",
      "============================================================\r\n",
      "Loading ONNX model from: /kaggle/working/AQUAFace/pretrained_models/R100_Glint360K.onnx\r\n",
      "‚úÖ ONNX model loaded successfully\r\n",
      "Model: r100\r\n",
      "Metric FC: arc_margin\r\n",
      "============================================================\r\n",
      "\r\n",
      "\r\n",
      "================================================================================\r\n",
      "üîç EVALUATING BASE MODEL (BEFORE TRAINING)\r\n",
      "================================================================================\r\n",
      "Validating Base Model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:12<00:00,  1.72it/s]\r\n",
      "\r\n",
      "üéØ Validation Results:\r\n",
      "  Validation pairs: 55543\r\n",
      "  ROC AUC: 0.9228\r\n",
      "  Optimal Threshold: 0.1923\r\n",
      "  Accuracy at Optimal Threshold: 0.9004\r\n",
      "  TPR at FPR=0.01%: 0.6779\r\n",
      "  TPR at FPR=0.1%:  0.7388\r\n",
      "  TPR at FPR=1%:    0.8082\r\n",
      "================================================================================\r\n",
      "\r\n",
      "\r\n",
      "üìä BASE MODEL PERFORMANCE:\r\n",
      "  ROC AUC: 0.9228\r\n",
      "  Accuracy: 0.9004\r\n",
      "  TPR@FPR=0.01%: 0.6779\r\n",
      "  TPR@FPR=1%: 0.8082\r\n",
      "\r\n",
      "================================================================================\r\n",
      "üöÄ NOW STARTING TRAINING...\r\n",
      "================================================================================\r\n",
      "\r\n",
      "============================================================\r\n",
      "Freezing Backbone - Fine-tuning Strategy\r\n",
      "============================================================\r\n",
      "Trainable parameters:\r\n",
      "  module.metric_fc.weight\r\n",
      "============================================================\r\n",
      "\r\n",
      "============================================================\r\n",
      "Training Configuration\r\n",
      "============================================================\r\n",
      "Optimizer: adam\r\n",
      "Learning rate: 0.002\r\n",
      "Loss function: CrossEntropyLoss\r\n",
      "============================================================\r\n",
      "\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 1/15\r\n",
      "============================================================\r\n",
      "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:21<00:00,  1.67it/s, loss=10.3665]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 10.1107\r\n",
      "  Person AUC: 0.8983\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8394\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.5279\r\n",
      "  Person AUC: 0.8855\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8289\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8855\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 2/15\r\n",
      "============================================================\r\n",
      "Epoch 2 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=8.9589]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2107\r\n",
      "  Person AUC: 0.8982\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8392\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:10<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.0800\r\n",
      "  Person AUC: 0.8990\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8434\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8990\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 3/15\r\n",
      "============================================================\r\n",
      "Epoch 3 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=7.8840]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2315\r\n",
      "  Person AUC: 0.8983\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8392\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 8.9329\r\n",
      "  Person AUC: 0.9029\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8475\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.9029\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 4/15\r\n",
      "============================================================\r\n",
      "Epoch 4 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=8.9643]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2413\r\n",
      "  Person AUC: 0.8981\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8389\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.4513\r\n",
      "  Person AUC: 0.8936\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8334\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8936\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 5/15\r\n",
      "============================================================\r\n",
      "Epoch 5 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=9.8047]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2445\r\n",
      "  Person AUC: 0.8982\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8388\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.5369\r\n",
      "  Person AUC: 0.8910\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8309\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8910\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 6/15\r\n",
      "============================================================\r\n",
      "Epoch 6 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=9.7154]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2453\r\n",
      "  Person AUC: 0.8983\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8391\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.1239\r\n",
      "  Person AUC: 0.9059\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8434\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.9059\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 7/15\r\n",
      "============================================================\r\n",
      "Epoch 7 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=9.4662]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2451\r\n",
      "  Person AUC: 0.8984\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8394\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.6458\r\n",
      "  Person AUC: 0.8863\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8284\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8863\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 8/15\r\n",
      "============================================================\r\n",
      "Epoch 8 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:21<00:00,  1.67it/s, loss=11.2711]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2441\r\n",
      "  Person AUC: 0.8985\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8395\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:10<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.6801\r\n",
      "  Person AUC: 0.8850\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8265\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8850\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 9/15\r\n",
      "============================================================\r\n",
      "Epoch 9 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:21<00:00,  1.67it/s, loss=10.6125]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2467\r\n",
      "  Person AUC: 0.8983\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8395\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.3117\r\n",
      "  Person AUC: 0.8958\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8379\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8958\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 10/15\r\n",
      "============================================================\r\n",
      "Epoch 10 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=10.8353]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2463\r\n",
      "  Person AUC: 0.8984\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8393\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.7281\r\n",
      "  Person AUC: 0.8869\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8291\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8869\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 11/15\r\n",
      "============================================================\r\n",
      "Epoch 11 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:21<00:00,  1.67it/s, loss=8.7019]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2149\r\n",
      "  Person AUC: 0.8981\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8395\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 8.9792\r\n",
      "  Person AUC: 0.9074\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8468\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.9074\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 12/15\r\n",
      "============================================================\r\n",
      "Epoch 12 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=9.7606]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2127\r\n",
      "  Person AUC: 0.8982\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8394\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.0322\r\n",
      "  Person AUC: 0.9059\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8462\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.9059\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 13/15\r\n",
      "============================================================\r\n",
      "Epoch 13 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=9.6280]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2151\r\n",
      "  Person AUC: 0.8984\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8394\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.3275\r\n",
      "  Person AUC: 0.8941\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8369\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8941\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 14/15\r\n",
      "============================================================\r\n",
      "Epoch 14 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=8.2968]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2106\r\n",
      "  Person AUC: 0.8983\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8389\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.73it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.1112\r\n",
      "  Person AUC: 0.8988\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8412\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.8988\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Epoch 15/15\r\n",
      "============================================================\r\n",
      "Epoch 15 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1736/1736 [17:20<00:00,  1.67it/s, loss=9.0869]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Train Metrics:\r\n",
      "  Loss: 9.2127\r\n",
      "  Person AUC: 0.8984\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8394\r\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 434/434 [04:11<00:00,  1.72it/s]\r\n",
      "Warning: Could not calculate age group AUC (only one class present)\r\n",
      "\r\n",
      "Validation Metrics:\r\n",
      "  Loss: 9.1066\r\n",
      "  Person AUC: 0.9015\r\n",
      "  Age Group AUC: 0.0000\r\n",
      "  Accuracy: 0.8416\r\n",
      "Best person_auc: 0.9228, Current person_auc: 0.9015\r\n",
      "Metric did not improve, not saving\r\n",
      "\r\n",
      "============================================================\r\n",
      "Training completed!\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca75f9a",
   "metadata": {
    "papermill": {
     "duration": 1.407321,
     "end_time": "2025-12-25T01:36:57.622010",
     "exception": false,
     "start_time": "2025-12-25T01:36:56.214689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 288036235,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19749.271401,
   "end_time": "2025-12-25T01:36:59.221642",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T20:07:49.950241",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
